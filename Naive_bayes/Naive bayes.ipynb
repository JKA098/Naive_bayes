{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfd28b43-9a1d-45cc-a8a2-67195ed82373",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Naïve Bayes (NB) classification algorithm - Assignment 3 (AMOD 5310H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cff56b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd                         # For reading CSV files\n",
    "import sklearn\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
    "from sklearn.metrics import accuracy_score            # For evaluating performance\n",
    "from collections import defaultdict                   # For managing nested dictionaries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb5ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5de21fa0-f196-4189-b9f8-1410a11fc98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Load your dataset\n",
    "# for understanding of the steps required[1],[2].\n",
    "df = pd.read_csv(\"sample_dataset.csv\")\n",
    "\n",
    "# Step 3: Split the dataset\n",
    "\n",
    "# reference of how to use iloc [3],[4],[5]\n",
    "\n",
    "X = df.iloc[:, :-1] # all columns except the last[selects all rows and all columns except the last one (i.e., the 4 features).]\n",
    "y = df.iloc[:, -1] # the last column[selects all rows of the last column only, which is the target (Occupied).]\n",
    "\n",
    "# split into training and test sets\n",
    "# reference of where I learned to do the following[6],[7].\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size= 0.2, random_state= 42 \n",
    ") \n",
    "# random_state=42: makes the split reproducible (you get the same split every time you run it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9ac8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a9d1f-7bf5-4c99-88f6-72baa8a249ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the following are the freqency of each class:\n",
      "\n",
      " The number of Yes is: 7\n",
      "\n",
      " The number of NO is: 4\n",
      "**************************\n",
      "\n",
      "the total number of classes: 11\n",
      "\n",
      "✅ Prior Probabilities:\n",
      "Class: Yes, P(Yes) = 0.6364\n",
      "Class: No, P(No) = 0.3636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"**************************\")\\n\\nprint(\\n    \"\\nPrior probabilities becimes:\",\\n    f\"\\nThe probability of Yes is: {priors[\\'Yes\\']:.4f}\",\\n    f\"\\nThe probability of No is: {priors[\\'No\\']:.4f}\"\\n)\\n\\nprint(\"**************************\")\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Calculate Prior Probabilities\n",
    "\"\"\"\n",
    "Prior probabilities\n",
    "P = counts of class y/ total number of samples in class y\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# get the frequency of each counts: Yes/No(classes).\n",
    "# reference for the following [8].\n",
    "counts = y_train.value_counts()\n",
    "print(f\"\\nthe following are the freqency of each class:\")\n",
    "print(f\"\\n The number of Yes is: {counts['Yes']}\")\n",
    "print(f\"\\n The number of NO is: {counts['No']}\")\n",
    "\n",
    "\n",
    "#  total number of training samples in class y\n",
    "total_counts = len(y_train) \n",
    "print(\"**************************\")\n",
    "print(f\"\\nthe total number of classes: {total_counts}\")\n",
    "\n",
    "# Divide each count by the total number of training samples.\n",
    "#p_yes = counts['Yes'] / total_counts\n",
    "#p_no = counts['No'] / total_counts\n",
    "\n",
    "# prior probability\n",
    "#priors = {\n",
    "#    \"Yes\": p_yes, \n",
    "#    \"No\": p_no\n",
    "#}\n",
    "\n",
    "# Automatically calculate priors for any class in the dataset\n",
    "priors = {}\n",
    "\n",
    "for cls in counts.index:\n",
    "    priors[cls] = counts[cls] / total_counts\n",
    "\n",
    "\n",
    "print(\"\\nPrior Probabilities:\")\n",
    "for cls, prob in priors.items():\n",
    "    print(f\"Class: {cls}, P({cls}) = {prob:.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "print(\"**************************\")\n",
    "\n",
    "print(\n",
    "    \"\\nPrior probabilities becimes:\",\n",
    "    f\"\\nThe probability of Yes is: {priors['Yes']:.4f}\",\n",
    "    f\"\\nThe probability of No is: {priors['No']:.4f}\"\n",
    ")\n",
    "\n",
    "print(\"**************************\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda69e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically calculate priors for any class in the dataset\n",
    "priors = {}\n",
    "\n",
    "for cls in counts.index:\n",
    "    priors[cls] = counts[cls] / total_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6db2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f40b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Overcast': {'Yes': 0.42857142857142855, 'No': 0.0}, 'Rain': {'Yes': 0.2857142857142857, 'No': 0.5}, 'Sunny': {'Yes': 0.2857142857142857, 'No': 0.5}}\n",
      "****************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Calculate Conditional probabilities\n",
    "\n",
    "# reference for understanding how Conditional probabilities works [9].\n",
    "\n",
    "\"\"\"Conditional probability\n",
    "P = count of( X=x and Y=y happening) / count of class y(it can be counts of Yes or Counts of No)\n",
    "\"\"\"\n",
    "\n",
    "conditional_probs = {} \n",
    "# reference for the following [10].\n",
    "features = X_train.columns\n",
    "classes = y_train.unique()\n",
    "\n",
    "\n",
    "# loop through each feature\n",
    "\n",
    "for feature in features:\n",
    "\n",
    "    conditional_probs[feature] = {} # initialize dictionary for storing, for this feature\n",
    "\n",
    "    unique_vals = X_train[feature].unique() # get all possible values for this feature\n",
    "\n",
    "    # loop through each value of the current feature\n",
    "\n",
    "    for val in unique_vals:\n",
    "        conditional_probs[feature][val] = {} # initialize dictionary to hold class probabilities\n",
    "        for cls in classes:\n",
    "            # Get all rows in X_train where class == cls\n",
    "            # also for the following a for loop would have been much more intuitive, but the code would get to long.\n",
    "            rows_with_class = X_train[y_train == cls] # this will give you the rows where you have either Yes/No, for a given feature\n",
    "            #print(f\"\\nthe following are all rows in X_train, where the label is Yes (or No): {rows_with_class}\")\n",
    "            # which allow to know how often each feature value (e.g., \"Sunny\") appears with a specific class  (e.g., \"Yes\")\n",
    "            #print(\"****************************************************************\")\n",
    "\n",
    "\n",
    "            # Count how many times feature value == val in those rows\n",
    "            count_feature_val = (rows_with_class[feature] == val).sum()  \n",
    "            #print(f\"\\nthe following are how many times feature value == val in those rows: {count_feature_val}\")\n",
    "            # It basically counts how many times the current feature has a specific value (like \"Sunny\") \n",
    "            # for a specific class (cls = \"Yes\" or \"No\").\n",
    "            #print(\"****************************************************************\")\n",
    "\n",
    "\n",
    "            # Count total number of row8-Puzzle A Searchs where class == cls\n",
    "            count_class = (y_train == cls).sum()\n",
    "            #print(f\"\\nthe following are the rows where class == cls: {count_class}\")\n",
    "            # This counts how many total times the class label cls (e.g., \"Yes\" or \"No\") appears in the training set\n",
    "            # for a specific value.\n",
    "            #print(\"****************************************************************\")\n",
    "\n",
    "\n",
    "            \n",
    "            prob = count_feature_val / count_class\n",
    "            conditional_probs[feature][val][cls] = prob\n",
    "print(conditional_probs['Outlook']) # to get an idea of how it looks like\n",
    "print(\"****************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e8253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d90b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Put everything together \n",
    "\n",
    "def predict_instance(instance, priors, conditional_probs):\n",
    "    \"\"\"\n",
    "    # here an instance is one full example from the dataset.\n",
    "    # it is all the feature values that describe one thing you're trying to classify.\n",
    "    # Outlook = Sunny, Temperature = Cool, Humidity = High, Wind = Strong\n",
    "    # it is colum and value in that colum for that row.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    posteriors={} # to store probability for each class\n",
    "    # loop through each possible class. the goal is to check the prior probability( how likely I am to find it)\n",
    "    for cls in priors:\n",
    "        print(f\"\\nEvaluating class: {cls}\")\n",
    "        prob = priors[cls] # this use the priors defined earlier in step 4\n",
    "        #print(f\"Prior P({cls}) = {prob:.4f}\")\n",
    "\n",
    "    # multiply with the conditional probabilities for each feature.\n",
    "    # to do that. first for each feature/column for a given row, grab the feature and value.\n",
    "        for feature in instance.index:\n",
    "            value = instance[feature] # the value of that feature in the instance\n",
    "            # which is slightly confusing because above I never created an instance list/dictionary\n",
    "            # but several hours of explantion from Gemini, conviced me that the code\n",
    "            # will know what it is doing, even if my brain is lagging behind.\n",
    "            \n",
    "            # this is the same as the conditional probability created above.\n",
    "            cond_prob = conditional_probs[feature][value][cls]\n",
    "            print(f\"Likelihood P({feature}={value} | {cls}) = {cond_prob:.4f}\")\n",
    "\n",
    "            # multiply the current probability(priors) to the conditional probability(cond_prob)\n",
    "            new_prob = prob * cond_prob\n",
    "            prob = new_prob\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"  Probability for each class {cls}: {prob:.4}\")\n",
    "        posteriors[cls]= prob\n",
    "\n",
    "    # choose the class with the highest posterior\n",
    "    # reference for the following [11].\n",
    "    predicted_class = max(posteriors, key = posteriors.get)\n",
    "    print(f\"\\nPredicted class: {predicted_class} with probability {posteriors[predicted_class]:.6f}\")\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd767fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce184e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating class: Yes\n",
      "Likelihood P(Outlook=Rain | Yes) = 0.2857\n",
      "Likelihood P(Temperature=Mild | Yes) = 0.2857\n",
      "Likelihood P(Humidity=Normal | Yes) = 0.7143\n",
      "Likelihood P(Wind=Weak | Yes) = 0.5714\n",
      "  Probability for each class Yes: 0.0212\n",
      "\n",
      "Evaluating class: No\n",
      "Likelihood P(Outlook=Rain | No) = 0.5000\n",
      "Likelihood P(Temperature=Mild | No) = 0.5000\n",
      "Likelihood P(Humidity=Normal | No) = 0.2500\n",
      "Likelihood P(Wind=Weak | No) = 0.2500\n",
      "  Probability for each class No: 0.005682\n",
      "\n",
      "Predicted class: Yes with probability 0.021203\n",
      "\n",
      "Evaluating class: Yes\n",
      "Likelihood P(Outlook=Overcast | Yes) = 0.4286\n",
      "Likelihood P(Temperature=Mild | Yes) = 0.2857\n",
      "Likelihood P(Humidity=High | Yes) = 0.2857\n",
      "Likelihood P(Wind=Strong | Yes) = 0.4286\n",
      "  Probability for each class Yes: 0.009541\n",
      "\n",
      "Evaluating class: No\n",
      "Likelihood P(Outlook=Overcast | No) = 0.0000\n",
      "Likelihood P(Temperature=Mild | No) = 0.5000\n",
      "Likelihood P(Humidity=High | No) = 0.7500\n",
      "Likelihood P(Wind=Strong | No) = 0.7500\n",
      "  Probability for each class No: 0.0\n",
      "\n",
      "Predicted class: Yes with probability 0.009541\n",
      "\n",
      "Evaluating class: Yes\n",
      "Likelihood P(Outlook=Sunny | Yes) = 0.2857\n",
      "Likelihood P(Temperature=Hot | Yes) = 0.2857\n",
      "Likelihood P(Humidity=High | Yes) = 0.2857\n",
      "Likelihood P(Wind=Weak | Yes) = 0.5714\n",
      "  Probability for each class Yes: 0.008481\n",
      "\n",
      "Evaluating class: No\n",
      "Likelihood P(Outlook=Sunny | No) = 0.5000\n",
      "Likelihood P(Temperature=Hot | No) = 0.2500\n",
      "Likelihood P(Humidity=High | No) = 0.7500\n",
      "Likelihood P(Wind=Weak | No) = 0.2500\n",
      "  Probability for each class No: 0.008523\n",
      "\n",
      "Predicted class: No with probability 0.008523\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Predict on the test set\n",
    "\n",
    "y_pred_prob = []\n",
    "\n",
    "# reference for the following [12].\n",
    "for index, row in X_test.iterrows():\n",
    "    prediction = predict_instance(row, priors, conditional_probs)\n",
    "    y_pred_prob.append(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9b5cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Calculate Accuracy\n",
    "# reference for the following[13]. \n",
    "accuracy = accuracy_score(y_test, y_pred_prob)\n",
    "print(f\"\\n Model accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8cbf95-7f47-421e-8cac-a68c004147d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
